---
layout: post
title:  "Beginner’s Guide to (Shannon) Entropy"
date:   2022-07-03 00:00:00 -0500
categories: methods
---

![the entropy man](/assets/entropy/entropy-man.png)

Entropy is a way to measure uncertainty. In this introduction we will build up
an intuition for what exactly entropy is measuring and go through the logic of
its axioms. We will explore entropy in terms of binary yes/no questions, the
answer to which is a single bit.

Here we go.

Say we’ve thrown a dart at a dart board. We are practiced enough to always hit
the board, but novice enough not to aim within the board. How much uncertainty
is there around what color on the board our dart has landed on?

## The two-color dartboard

![a dartboard with two colors](/assets/entropy/two_frame1.png)

In the simplest case with only two colors, asking yes/no questions makes sense.
We can first ask ‘Is the dart in the blue region?’ and whatever the answer is,
we’ve located the dart!

In effect, the answer to our question allows us to cut through the dart board
*exclude* the half that does not contain the dart. We will see this throughout our
examples here. Because our simple board contains only two colors, each with its
own half, excluding half of the board is sufficient. We know that the dart has
landed on the orange region.

![animation showing how yes/no questions exclude part of the board](/assets/entropy/two_animation-1.gif)

> Animation demonstrating how the question affects our understanding of the board.

Its important to note that this is a property of the board, not the dart.
Regardless of which color the dart landed on, it could only ever take one yes/no
question to find it. This means that before we threw the dart we had an
uncertainty of where it would land equal to one yes/no question. A *binary*
question.

## Adding more colors to the board

![four-color dartboard](/assets/entropy/four_frame1.png)

Now let’s move on to a slightly more interesting dart board. We could pursue the
same line of questioning but if we ask about each color sequentially, we might
have to ask up to three questions. Obviously, given the structure of the board,
we can do better than that. If instead, we ask about the top and, say, the left
on the board we can always get it in two.

![four-color dartboard animation](/assets/entropy/four_animation.gif)

In this case we first ask ‘Is the dart in the top half?’ and get the answer
‘yes’. This allows us to exclude the bottom half of the dart board. We know that
the dart can’t be there!

Next, we ask ‘is the dart in the left half?’ and get the answer ‘no’ which lets
us exclude the left half. This tells us that the dart can only be in the top
right, or blue, section.

The fact that we had to ask two questions tells us that our uncertainty was
greater about the color of the region the dart landed on. This should make
sense, your more likely to be wrong guessing one in four than one in two. As
more values are added our ability to guess the outcome decreases—our uncertainty
increases.

This same logic applies as we add more colors. Let’s say we have an eight color
dart board. In this case we will need to ask an additional question. Top or
bottom, left or right, and above or below the diagonal.

![eight-colored dartboard under successive exclusion by binary questions](/assets/entropy/eight_animation.gif)

Each time we have doubled the number of options and the number of questions
we’ve had to ask has increased by one. This is no accident, it is a consequence
of the fact that we are asking binary questions. The number of questions we need
to ask is related to the base-2 logarithm of the number of options.

$$
\begin{align}
\log_2 2 &= 1 \\
\log_2 4 &= 2 \\
\log_2 8 &= 3 \\
\log_2 16 &= 4\\
… 
\end{align}
$$

Unfortunately for us, most numbers are not powers of two and so most dart boards
will not be answerable in an integer number of questions.

## Partial Yes/No questions??

n this dart board example, we formulated yes/no questions as straight lines that
split the space in half through the center of the circle. While the eight-color
board with the diagonal line my appear different, the diagonal line still
divided the space remaining after the first two exclusions perfectly in half.

We shall now turn toward a case where we can’t cut the remaining space neatly in
half.

![three color dart board is hard to cut](/assets/entropy/three_animation.gif)

n a board with three colors. Based on the two- and four-color boards we should
expect to need between one and two yes/no questions. This time, however, after
the first cut we are left with an imbalance in the colors on the dart board.

Unlike before, after our first exclusion we are not completely in the dark. If
we know that the dart is in the top half of the board and instead of asking
another question we simply assume its in the blue we will usually be right. We
are not currently equipped to handle this case.

However, it is sort of obvious that we will need between one and two questions
if we pursue the naive line of questioning where we ask about each color one by
one. Sometimes we will get lucky and ask about the correct color in our first
question but usually we need two.

We will now turn our attention to building the tools we need to quantify
uncertainty regardless of the structure of our dartboard.

## Requirements for a useful measure of uncertainty

We will begin by thinking about what characteristics our measure of uncertainty
should have. We’ve seen examples of two of them and the other will be quite
obvious in retrospect.

### Maximization

The board following our first cut on the three-color board illustrates when our
uncertainty is not at a maximum: any time the outcomes are not equally likely.
To think about why this is true, let’s think about a very extreme case.

![a very imbalanced game board](/assets/entropy/extreme_board.gif)

On the board above, we will almost always be correct if we simply guess that the
dart will land on blue. There is obviously less uncertainty here than in the two
halves above. As we make the color regions more and more similarly sized we will
see a greater likelihood of darts landing in the orange region. Even before
throwing the dart we will have greater uncertainty of where it will land.

![a less imbalanced game board](/assets/entropy/less_extreme_board.gif)

When the regions are equal in size, however, the board gives us no indication of
where our darts will land. We will never have a hint as to which color the dart
might land in and so our uncertainty is maximal.

### Nestedness

We described uncertainty in terms of asking a series of questions that allow us
to exclude some outcomes. This approach will highlight the least intuitive
requirement for our measurement.

Take the four-color dartboard. All we actually did was throw a single dart at
one of four options, yet the description was of a sequential nested process in
which we looked at the top or bottom half and then the left or right. We can
visualize both of these processes as trees.

![tree diagram of the four-color dartboard](/assets/entropy/combined_tree.png)

> On the left we see the "real" probabilities of the dart landing in a given
> color. On the right, we see the probabilities reformulated as excluding cuts
> accross the dartboard.

The diagram on the left illustrates how when we throw the dart it will land on
one of the four colors each with a probability of $\frac{1}{4}$. The diagram on
the right shows how we first cut through the board to chose the top or bottom
half, then asked about the colors. Each was a binary choice of two equally
likely outcomes. Each branch is labeled with its probability of occurring—the
probability of the answer to our question of it being “yes.” We can follow the
branches by multiplying their probabilities together to see that each outcome
still occurs with a probability of $\frac{1}{4}$.

Given that these two diagrams are equivalent, our measure of uncertainty should
produce the same result for either of them. The nested structure and the
intuition of cutting across the dart board should help here.

The uncertainty about whether the dart is in the top or bottom half is there
regardless of which branching structure we are thinking about. Then there is
some additional uncertainty about the specific colors within those half. Of
course, we only need to address each of these additional sources of uncertainty
half of the time. Half of the time we care about uncertainty within the top,
half of the time we care about uncertainty within the bottom. 

Lets say we want to call our uncertainty measure $H$ for no particular reason.
[Perhaps we meant to use a Greek
symbol](https://math.stackexchange.com/a/84743). We can formalize this logic as
follows:

$$
H(\{P_{blue}, P_{orange}, P_{green}, P_{red}\}) = H(\{P_{top}, P_{bottom}\}) + \\
P_{top} H(\{P_{blue}^{top}, P_{orange}^{top}\}) + P_{bottom}
H(\{P_{green}^{bottom}, P_{red}^{bottom}\})
$$

To make this concrete with the values shown in the diagrams above this is:

$$
H\left(\left\{\frac{1}{4}, \frac{1}{4}, \frac{1}{4}, \frac{1}{4}\right\}\right) =  H\left(\left\{\frac{1}{2}, \frac{1}{2}\right\}\right) + \frac{1}{2} H\left(\left\{\frac{1}{2}, \frac{1}{2}\right\}\right) + \frac{1}{2} H\left(\left\{\frac{1}{2}, \frac{1}{2}\right\}\right)
$$

This is a pretty strict constraint! It tells us that the uncertainty remaining
after an exclusion is added onto the uncertainty of the initial exclusions and
that this weighted sum must be consistent with the unnested case where we think
about making the decision all at once.

### Continuity

Our third requirement is probably obvious enough not to have given it any
thought. Let’s say we modified our four-color board slightly, growing the orange
region slightly, and shrinking the green region to compensate.

![a slightly uneven four-color dartboard](/assets/entropy/uneven_board.png)

The board is pretty similar. We’ve established that when the colors were all
equally likely we needed two questions. We’ve also established that our
uncertainty should be maximized. This means that we should have have less
uncertainty that the original four-color board. However, the regions are all
still roughly the same size so the difference should be small.

In fact, if we make arbitrarily small changes to the board, we should see
corresponding arbitrarily small changes in our uncertainty. Similarly when we
make large changes to the board we should see large changes in our measurement.
This is what we mean by continuity of our measurement and it is the third and
final requirement we need to finally start measuring uncertainty.

## Axioms and Entropy

n Claude Shannon’s landmark paper “A Mathematical Theory of Communication,”
Shannon laid out our three requirements as the axioms of the uncertainty measure
he develops. In his own words:

> If there is such a measure, say $H(p_1; p_2;…;p_n)$, it is reasonable to
> require of it the following properties:
> 
> 1. $H$ should be continuous in the $p_i$.
> 1. If all the $p_i$ are equal, $p_i = \frac{1}{n}$, then $H$ should be a
> monotonic increasing function of $n$. With equally likely events there is more
> choice, or uncertainty, when there are more possible events.
> 1. If a choice be
> broken down into two successive choices, the original $H$ should be the
> weighted sum of the individual values of $H$.

In our terms, these are continuity, maximization, and nestedness, respectively.
Amazingly, there is *exactly one* formula that satisfies these requirements:

$$
H(X) = -K \sum_{i=1}^N p(x_i) \log p(x_i)
$$

As an aside, Shannon allegedly was unsure of what to call this thing until [a
conversation with mathematician John von
Neumann](https://www.eoht.info/page/Neumann-Shannon%20anecdote). Von Neumann
pointed out the similarity to the formula for entropy from statistical physics
and also told Shannon that no one really gets entropy anyway so if he were to
chose that name no one could argue with it.

We can use this measurement on any probability distribution to measure its
uncertainty. Of course its trickier on continuous probability distributions.

What entropy really tells us is the number of yes/no questions we need to ask on
average if we are maximally efficient in the questions we ask. Try it on the
dart boards if you don't believe me.

Let’s finish up by looking at a new dartboard examples to ensure that entropy is
doing what we think it is doing.

## Dartboard Entropy

Now that we know the equation for entropy we can go head and implement it in
Python. In fact its ridiculously easy to do with NumPy.

{% highlight python %}
import numpy as np
from numpy.typing import ArrayLike

def H(x: ArrayLike) -> float:
    return -np.sum(x * np.log2(x))
{% endhighlight %}

Now we need to encode our dartboards as probability distributions. If our dart
is equally likely to land anywhere on the board than the probability of landing
in any particular region is proportional to the size of the region.

![dartboard encoded as probability distribution](/assets/entropy/dartboard_probability.png)

We can use NumPy arrays to hold these probabilities and pass them to our
function to get the entropy for the encoded dartboards. For dartboard shown
above, we can already guess that the entropy will be less than two bits. The
four-color board above with evenly sized regions required two questions and by
the maximization axiom, that must be the largest possible uncertainty for a
board with four colors.

{% highlight python %}
example_board = np.array([0.333, 0.125, 0.153, 0.389])

print(f"Entropy of the example dartboard: {H(example_board):.3f} bits")
{% endhighlight %}

```text
Entropy of the example dartboard: 1.847 bits
```

As expected, we get close to but not quite two bits. That means we on average we
need almost but not quite two yes/no questions to locate the dart on the board.

While we're at it, let’s check the dartboards with even spacing to ensure that
entropy is consistent with our thinking about splitting the board with yes/no
questions.

{% highlight python %}
# two region board
x_two = np.array([1/2, 1/2])

# more succinctly
x_four = np.ones(4) * 1/4
x_eight = np.ones(8) * 1/8

print(f"Entropy of the two-color dart board: {H(x_two):.3f} bits")
print(f"Entropy of the four-color dart board: {H(x_four):.3f} bits")
print(f"Entropy of the eight-color dart board: {H(x_eight):.3f} bits")
{% endhighlight %}

```text
Entropy of the two-color dart board: 1.000 bits
Entropy of the four-color dart board: 2.000 bits
Entropy of the eight-color dart board: 3.000 bits
```

As expected, entropy gives us numbers that match the ones we came up with by
excluding halves of the board. Finally, we can address the three-color board.

{% highlight python %}
x_three = np.ones(3) * 1/3
print(f"Entropy of the three-color dart board: {h(x_three):.3f} bits")
{% endhighlight %}

```text
Entropy of the three-color dart board: 1.585 bits
```

As we claimed above, we get a noninteger value between 1 and 2.

## Conclusions

In this post we’ve built up an intuitive understanding of uncertainty and how we
can think of it in terms of yes/no questions, we explored the axioms laid out by
Claude Shannon in his development of entropy, and we’ve calculated entropy for
some simple examples. Entropy is powerful and useful by itself and provides the
foundation upon which all of information theory is built. It sees uses across
all scientific disciplines as a way to analyze probability distributions or
measure evenness of observations.

One case where entropy has seen application far from anything normally having to
do with where we normally encounter bits is in the study of biodiversity.
Typically the first measurement used in characterizing the biodiversity in a
given ecosystem is the species richness, $S$. This is simply the total number of
species observed in a location. 

The second second measure used when trying to characterize the biodiversity of a
place is usually what the ecologists call evenness or the Shannon-Wiener index.
This quantifies the extent to which all species are equally abundant. We
calculate the Shannon-Wiener index by counting all individuals in each species
at our location and then turning those numbers into frequencies.

Say we’re studying a forest and for some sample site we find five maple, four
beech, two oak, and three hickory trees. This gives us a species richness of $S=4$ and
a data set that looks something like this:

$$
T = \{5, 4, 2, 3\}
$$

We can turn the values in $T$ into frequencies by dividing each value by the
total number of trees observed. This gives us a frequency distribution that
looks like:

$$
X = \{0.357, 0.286, 0.143, 0.214\}
$$

The Shannon-Wiener index is given by the entropy normalized to between zero and
one by the maximum entropy possible for the number of species observed:

$$
E_H = \frac{H(X)}{\log_2(S)}
$$

However, this quantity is not limited to ecology. It is useful in any situation
in which its useful to measure inequality between observations, something like
the [gini coefficient](https://en.wikipedia.org/wiki/Gini_coefficient). Maybe,
instead you are a machine learning engineer and you want to know the performance
of a decision tree, entropy of the decision is a great way to do that. Better
trees will produce more even splits.

In later posts I will build on this foundation to explore mutual information and
transfer entropy, two very powerful tools in data analysis. For now, at least,
we can at least prove von Neumann wrong: some people do understand entropy.
